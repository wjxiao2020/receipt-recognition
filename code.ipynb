{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e283f36b",
   "metadata": {},
   "source": [
    "# Receipt Recognition System \n",
    "\n",
    "We aim to build a receipt recognition and information extraction system that could answer questions based on information on a given receipt photo. We want it to not only be able to correctly extract out the exact numeric value on the receipt when such task is given, but also to answer more complex questions that involve some math calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfba9ca",
   "metadata": {},
   "source": [
    "## Loading and testing out the vision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67d9f72-aa5d-40ca-9cb6-bccae580ecac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07b297ee-4465-4da1-bb8f-a4c05acdfbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3487bd56-96c2-4657-bda5-764f4386e636",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 03:25:26.786551: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-25 03:25:26.786587: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-25 03:25:26.786617: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-25 03:25:26.794093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e0a26ba04749cfaef54554d7261d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "access_token = \"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\"\n",
    "# Hugging Face model id\n",
    "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    token=access_token\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_id,\n",
    "    token=access_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e501e22-7f6d-4a7b-a419-bcf8a7402607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt and extract the same type of information (Store Name, Date, Items, Tax, and Total).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Receipt Information**\n",
      "\n",
      "* **Store Name:** Not visible on the receipt\n",
      "* **Date:** Not visible on the receipt\n",
      "* **Items:**\n",
      "\t+ Nasi Campur Bali\n",
      "\t+ Bok Bengil Nasi\n",
      "\t+ MilkShake Starwb\n",
      "\t+ Ice Lemon Tea\n",
      "\t+ Nasi Ayam Dewata\n",
      "\t+ Free Ice Tea\n",
      "\t+ Organic Green Sa\n",
      "\t+ Ice Tea\n",
      "\t+ Ice Orange\n",
      "\t+ Ayam Suir Bali\n",
      "\t+ Tahu Goreng\n",
      "\t+ Tempe Goreng\n",
      "\t+ Tahu Telor Asin\n",
      "\t+ Nasi Goreng Samb\n",
      "\t+ Bok Panggang Sam\n",
      "\t+ Ayam Sambal Hija\n",
      "\t+ Hot Tea\n",
      "\t+ Ice Kopi\n",
      "\t+ Tahu Telor Asin\n",
      "\t+ Free Ice Tea\n",
      "\t+ Bebek Street\n",
      "\t+ Ice Tea Tawar\n",
      "* **Tax:** Not visible on the receipt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_path = \"receipt-recognition/receipt_00000.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": \"Read the following receipt and extract the same type of information (Store Name, Date, Items, Tax, and Total).\"}\n",
    "    ]}\n",
    "]\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "output = model.generate(**inputs, max_new_tokens=200)\n",
    "print(processor.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82357a4b",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We have created a jsonl file with 11 evaluation benchmark questions. From the following result, we could see that the model have a high accuracy on pure information extraction question, which means that the model can recognize the text on receipts very well. But when it answer questions that involve math calculation, such as unit price and total payment after a tax is applied, it has a very bad accuracy using the current basic prompting. We will try out more sophisticated prompting skills to help the model make a better decision on those types of more complex problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf99d92-ebb6-40fb-a26c-0ba8188dc4df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image path: receipt-recognition/receipt_00000.png\n",
      "question: What is the total payment amount?\n",
      "Expected Answer: 1591600\n",
      "\n",
      "Image path: receipt-recognition/receipt_00000.png\n",
      "question: How much was spent on hot tea in total ?\n",
      "Expected Answer: 44000\n",
      "\n",
      "Image path: receipt-recognition/receipt_00000.png\n",
      "question: What is the unit price of hot tea?\n",
      "Expected Answer: 22000\n",
      "\n",
      "Image path: receipt-recognition/receipt_00000.png\n",
      "question: How much does the ice tea cost?\n",
      "Expected Answer: 18000\n",
      "\n",
      "Image path: receipt-recognition/receipt_00000.png\n",
      "question: How much does the free ice tea cost?\n",
      "Expected Answer: 0\n",
      "\n",
      "Image path: receipt-recognition/receipt_00000.png\n",
      "question: How many Bbk Panggang Sam was bought?\n",
      "Expected Answer: 3\n",
      "\n",
      "Image path: receipt-recognition/receipt_00000.png\n",
      "question: How much is the service fee?\n",
      "Expected Answer: 10950\n",
      "\n",
      "Image path: receipt-recognition/receipt_00000.png\n",
      "question: If a 10% tax is applied on the subtotal, what will the total payment now be?\n",
      "Expected Answer: 1726200\n",
      "\n",
      "Image path: receipt-recognition/receipt_00026.png\n",
      "question: What percentage of tax was applied?\n",
      "Expected Answer: 10\n",
      "\n",
      "Image path: receipt-recognition/receipt_00026.png\n",
      "question: How much cash was given?\n",
      "Expected Answer: 50.5\n",
      "\n",
      "Image path: receipt-recognition/receipt_00026.png\n",
      "question: How much was the change given back?\n",
      "Expected Answer: 34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'qa.jsonl'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        print(f\"Image path: {data['image_path']}\")\n",
    "        print(f\"question: {data['question']}\")\n",
    "        print(f\"Expected Answer: {data['expected']}\")\n",
    "        print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f55f9788-f7f7-407c-8595-93dc4dea1331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image path: receipt_00000.png\n",
      "question: What is the total payment amount?\n",
      "Expected Answer: 1591600\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. What is the total payment amount?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "1,591,600.<|eot_id|>\n",
      "\n",
      "Image path: receipt_00000.png\n",
      "question: How much was spent on hot tea in total ?\n",
      "Expected Answer: 44000\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. How much was spent on hot tea in total?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "44,000.<|eot_id|>\n",
      "\n",
      "Image path: receipt_00000.png\n",
      "question: What is the unit price of hot tea?\n",
      "Expected Answer: 22000\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. What is the unit price of hot tea?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "44,000.<|eot_id|>\n",
      "\n",
      "Image path: receipt_00000.png\n",
      "question: How much does the ice tea cost?\n",
      "Expected Answer: 18000\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. How much does the ice tea cost?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "18,000.<|eot_id|>\n",
      "\n",
      "Image path: receipt_00000.png\n",
      "question: How much does the free ice tea cost?\n",
      "Expected Answer: 0\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. How much does the free ice tea cost?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "0<|eot_id|>\n",
      "\n",
      "Image path: receipt_00000.png\n",
      "question: How many Bbk Panggang Sam was bought?\n",
      "Expected Answer: 3\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. How many Bbk Panggang Sam was bought?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "3.<|eot_id|>\n",
      "\n",
      "Image path: receipt_00000.png\n",
      "question: How much is the service fee?\n",
      "Expected Answer: 10950\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. How much is the service fee?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "100,950.<|eot_id|>\n",
      "\n",
      "Image path: receipt_00000.png\n",
      "question: If a 10% tax is applied on the subtotal, what will the total payment now be?\n",
      "Expected Answer: 1726200\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. If a 10% tax is applied on the subtotal, what will the total payment now be?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "1,647,100.<|eot_id|>\n",
      "\n",
      "Image path: receipt_00026.png\n",
      "question: What percentage of tax was applied?\n",
      "Expected Answer: 10\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. What percentage of tax was applied?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "10.0<|eot_id|>\n",
      "\n",
      "Image path: receipt_00026.png\n",
      "question: How much cash was given?\n",
      "Expected Answer: 50.5\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. How much cash was given?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "50.500<|eot_id|>\n",
      "\n",
      "Image path: receipt_00026.png\n",
      "question: How much was the change given back?\n",
      "Expected Answer: 34\n",
      "Model Output: <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Read the following receipt. How much was the change given back?. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "34.000.<|eot_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'qa.jsonl'\n",
    "\n",
    "def format_question_prompt(question):\n",
    "    return f\"Read the following receipt. {question}. Respond in a sigle numeric value or 'not found' if it doesn't exist in the given image.\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        print(f\"Image path: {data['image_path']}\")\n",
    "        print(f\"question: {data['question']}\")\n",
    "        print(f\"Expected Answer: {data['expected']}\")\n",
    "        \n",
    "        image_path = data['image_path']\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": format_question_prompt(data['question'])}\n",
    "            ]}\n",
    "        ]\n",
    "        input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "        inputs = processor(\n",
    "            image,\n",
    "            input_text,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        output = model.generate(**inputs, max_new_tokens=200)\n",
    "        print(f\"Model Output: {processor.decode(output[0])}\")\n",
    "        print() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
